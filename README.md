# ğŸ¤– Y-DATA LangGraph Data Analyst Agent

Final project for the **Agentic Systems** course, part of the **Y-DATA 2024â€“2025** program.  
This repository contains an interactive **LangGraph-based data analysis agent** that can answer user questions about the [Bitext â€“ Customer Service Tagged Training dataset](https://huggingface.co/datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset).  

It extends the first assignment (basic ReAct agent) by re-implementing it in **LangGraph** and adding **conversation memory, persistence, and a corresponding Streamlit interface**.

---

## âœ¨ Features

- ğŸ§­ **Router Node** â€“ classifies queries into:  
  - Structured  
  - Unstructured  
  - Memory  
  - Out-of-scope

- ğŸ“Š **Structured Query Agent** â€“ supports:  
  - Counting categories or intents  
  - Showing examples  
  - Getting distributions  
  - Sorting dictionaries, summing values, etc.

- ğŸ“ **Unstructured Query Agent** â€“ performs **summarization across dataset batches** with dedicated prompts.

- ğŸš« **Out-of-scope Handler** â€“ returns polite fallback responses.

- ğŸ§  **Summarized Memory Node** â€“ stores & retrieves **concise user memories** across sessions.

- ğŸ’¾ **Persistence** â€“  
  - User & thread IDs, histories stored in **SQLite**  
  - **LangGraph checkpoints** for conversation state  
  - **SQLite store** for summarized memory

- ğŸ’» **Streamlit Interface** â€“  
  - User & thread management  
  - Conversation history view  
  - Query submission & results

---

## âš™ï¸ Tech Stack

- [LangChain](https://python.langchain.com/) & [LangGraph](https://langchain-ai.github.io/langgraph/) â€“ agent orchestration  
- [OpenAI GPT-4o-mini](https://platform.openai.com/) â€“ LLM backbone  
- [HuggingFace Datasets](https://huggingface.co/docs/datasets/) â€“ Bitext dataset  
- [Streamlit](https://streamlit.io/) â€“ web UI  
- [SQLite](https://www.sqlite.org/) â€“ persistence (checkpoints, store, user/thread DBs)  
- [Pydantic](https://docs.pydantic.dev/) â€“ structured outputs  
- [dotenv](https://pypi.org/project/python-dotenv/) â€“ environment variables

---

## ğŸš€ Installation & Setup

Tested with **Python 3.13.7**.

1. **Clone the repository**
   ```bash
   git clone https://github.com/OphirTuretz/Y-DATA-LangGraph-Data-Analyst.git
   cd Y-DATA-LangGraph-Data-Analyst
   ```

2. **Create a virtual environment**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   # Open .env and set your OpenAI API key:
   # OPENAI_API_KEY=sk-...
   ```

5. **Run the Streamlit app**
   ```bash
   streamlit run DataAnalyst.py
   ```

6. **(Optional) Reset the environment**
   ```bash
   python cleanup.py
   ```

---

## ğŸ§  LangGraph Architecture

<p align="center">
  <img src="images/Architecture_Diagram.svg" alt="LangGraph workflow diagram" />
</p>

- **Router Node** â†’ classifies the query.  
- **Structured Agent** â†” **Structured Tools** (loop until completion).  
- **Unstructured Agent** â†” **Unstructured Tools** (loop until completion).  
- **Out-of-scope Handler** â†’ returns polite response.  
- **Memory Nodes** â€“ `save_memory` after each turn, `read_memory` when asked.  
- **Checkpointer + Store** â€“ ensure state and memories persist.  

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ DataAnalyst.py              # Streamlit front-end
â”œâ”€â”€ engine.py                   # Query processing wrapper
â”œâ”€â”€ graph.py                    # LangGraph workflow definition
â”œâ”€â”€ graph_state.py              # Shared state schema
â”œâ”€â”€ structured_query_agent.py   # Structured agent + tools
â”œâ”€â”€ unstructured_query_agent.py # Unstructured agent + summarization
â”œâ”€â”€ out_of_scope_query_handler.py
â”œâ”€â”€ summarized_memory.py        # Save/read memory nodes
â”œâ”€â”€ id_manager.py               # User & thread persistence (SQLite)
â”œâ”€â”€ data.py                     # Dataset wrapper
â”œâ”€â”€ general_tools.py            # Shared tools
â”œâ”€â”€ cleanup.py                  # Utility to reset DBs
â”œâ”€â”€ app/const.py                # Config & constants
â”œâ”€â”€ prompts/                    # System prompt templates
â”œâ”€â”€ images/                     # Diagrams
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

---

## ğŸ’¡ Example Queries

**Structured**
- *What are the most frequent categories?*  
- *Show 3 examples from the REFUND category*  

**Unstructured**
- *Summarize how agents respond to payment issues*  

**Memory**
- *What do you remember about me?*  

**Out-of-scope**
- *Who is Magnus Carlsen?*  

---

## ğŸ“– Notes

- Assignment: **Final project in Agentic Systems course (Y-DATA 2025)**  
- Python version: **3.13.7**  
- Dataset: [Bitext â€“ Customer Service Tagged Training](https://huggingface.co/datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset)  
- LangSmith integration available but optional (see `.env.example`)  